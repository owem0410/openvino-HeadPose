#!/usr/bin/env python

from __future__ import print_function
import sys
import os
from argparse import ArgumentParser, SUPPRESS
import cv2
import numpy as np
import logging as log
import time
from openvino.inference_engine import IENetwork, IECore

import socket


def build_argparser():
    parser = ArgumentParser(add_help=False)
    args = parser.add_argument_group("Options")
    args.add_argument('-h', '--help', action='help', default=SUPPRESS, help='Show this help message and exit.')
    args.add_argument("-m", "--model", help="Required. Path to an .xml file with a trained model.",
        required=True, type=str)

    #add head pose model path
    args.add_argument("-m_hp", "--model_hp", help="Required. Path to an .xml file with a head posetrained model.",
        required=True, type=str)
    '''
    args.add_argument("-i", "--input", help="Required. Path to image file.",
        required=True, type=str, nargs="+")
    '''
    args.add_argument("-l", "--cpu_extension",
        help="Optional. Required for CPU custom layers. Absolute path to a shared library with the kernels implementations.",
        type=str, default=None)
    args.add_argument("-d", "--device",
        help="Optional. Specify the target device to infer on; CPU, GPU, FPGA or MYRIAD is acceptable. Sample will look for a suitable plugin for device specified (CPU by default)",
        default="CPU", type=str)
    args.add_argument("--labels", help="Optional. Labels mapping file", default=None, type=str)
    args.add_argument("-nt", "--number_top", help="Optional. Number of top results", default=10, type=int)
    
    return parser

def shapshot():
    start = time.time()
    cap = cv2.VideoCapture(0)
    _ , frame = cap.read()
    end = time.time()
    print(str(end-start))
    return frame

def read_ir(xml_path):
    model_xml = xml_path
    model_bin = os.path.splitext(model_xml)[0] + ".bin"
    log.info("Loading network files:\n\t{}\n\t{}".format(model_xml, model_bin))
    net = IENetwork(model=model_xml, weights=model_bin)
    return net

def check_cpu_support(net,device):
    if "CPU" in device:
        supported_layers = ie.query_network(net, "CPU")
        not_supported_layers = [l for l in net.layers.keys() if l not in supported_layers]
        if len(not_supported_layers) != 0:
            log.error("Following layers are not supported by the plugin for specified device {}:\n {}".
                      format(device, ', '.join(not_supported_layers)))
            log.error("Please try to specify cpu extensions library path in sample's command line parameters using -l "
                      "or --cpu_extension command line argument")
            sys.exit(1)
def main():
    log.basicConfig(format="[ %(levelname)s ] %(message)s", level=log.INFO, stream=sys.stdout)
    args = build_argparser().parse_args()
    # --------------------------- 1. Read IR Generated by ModelOptimizer (.xml and .bin files) ------------
    #device = args.device
    net_fd = read_ir(args.model)
    net_hp = read_ir(args.model_hp)
    # ------------- 2. Load Plugin for inference engine and extensions library if specified --------------
    log.info("Loading Inference Engine")
    ie = IECore()
    log.info("Device info:")
       
    if args.cpu_extension and "CPU" in args.device:
        ie.add_extension(args.cpu_extension, "CPU")
        log.info("CPU extension loaded: {}".format(args.cpu_extension))

    #check_cpu_support(net_fd)
    #check_cpu_support(net_hp)


    # --------------------------- 3. Read and preprocess input --------------------------------------------
    #face detection model
    input_blob = next(iter(net_fd.inputs))
    n, c, h, w = net_fd.inputs[input_blob].shape
    exec_net_fd = ie.load_network(network=net_fd, device_name=args.device)

    ##headpose model
    input_blob_hp = next(iter(net_hp.inputs))
    exec_net_hp = ie.load_network(network=net_hp, device_name=args.device)

    HOST = '127.0.0.1'
    PORT = 55555
    ADDRESS = (HOST, PORT)

    clientSocket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
    clientSocket.connect(ADDRESS)
    while True:
        
        msg = clientSocket.recv(1024)
        msg = msg.decode('utf-8')       
        ## image process
        if msg == 'angle': 
            
            images_hw = []        
            tmp_image = shapshot()       
            ih, iw = tmp_image.shape[:-1]        
            images_hw.append((ih, iw))
        
            if (ih, iw) != (h, w):
        
                image = cv2.resize(tmp_image, (w, h))
        
            image = image.transpose((2, 0, 1))  # Change data layout from HWC to CHW
        
            # --------------------------- 4. Configure input & output ---------------------------------------------        
            # --------------------------- Prepare input blobs -----------------------------------------------------        
            out_blob = next(iter(net_fd.outputs))        
            # --------------------------- Performing face detection inference ----------------------------------------------------        
            res = exec_net_fd.infer(inputs={input_blob: image})        
            # --------------------------- Read and postprocess output ---------------------------------------------
            res = res[out_blob]        
            boxes, classes = {}, {}        
            data = res[0][0]
        
            for number, proposal in enumerate(data):
        
                if proposal[2] > 0:
        
                    imid = np.int(proposal[0])        
                    ih, iw = images_hw[imid]        
                    label = np.int(proposal[1])        
                    confidence = proposal[2]        
                    xmin = np.int(iw * proposal[3])       
                    ymin = np.int(ih * proposal[4])       
                    xmax = np.int(iw * proposal[5])        
                    ymax = np.int(ih * proposal[6])
        
                    if proposal[2] > 0.5:       
                        print("confidence :"+ str(confidence))        
                        if not imid in boxes.keys():        
                            boxes[imid] = []        
                        boxes[imid].append([xmin, ymin, xmax, ymax])        
                        if not imid in classes.keys():       
                            classes[imid] = []       
                        classes[imid].append(label)        
                    else:
                        pass
            '''         
            for imid in classes:
                tmp_image = cv2.imread(args.input[imid])
            '''
            '''
            for box in boxes[imid]:
                cv2.rectangle(tmp_image, (box[0], box[1]), (box[2], box[3]), (232, 35, 244), 2)
                cv2.imwrite("out.bmp", tmp_image)
            '''
        #log.info("Image out.bmp created!")
            # -----------------------------------------------------------------------------------------------------       
            #---------head pose inference        
            ##[ymin:ymax,xmin,xmax]       
            for box in boxes[0]:
        
                tmp_image = tmp_image[box[1]:box[3],box[0]:box[2]]
        
            tmp_image = cv2.resize(tmp_image, (60, 60))        
            head_image = tmp_image.transpose((2, 0, 1))
            
            res_hp = exec_net_hp.infer(inputs={input_blob_hp: head_image})        
            #print(res_hp['angle_p_fc'])       
            #print(res_hp['angle_r_fc'])       
            #print(res_hp['angle_y_fc'])        
            angle = str(res_hp['angle_p_fc'][0][0]) + ',' + str(res_hp['angle_r_fc'][0][0]) + ',' + str(res_hp['angle_y_fc'][0][0])+','        
            clientSocket.send(angle.encode('utf-8'))

        else:        
            break
    
    clientSocket.close()
if __name__ == '__main__':
    sys.exit(main() or 0)